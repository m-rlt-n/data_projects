{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Dependencies\n",
    "\n",
    "from glob import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Pull in Amazon and Shopify order data\n",
    "\n",
    "# combine all amazon FBA & FBM csv files since can only download by month\n",
    "amazon_customers = sorted(glob('.../fba_order_data_****_**.csv'))\n",
    "amazon_all = pd.concat((pd.read_csv(file, encoding='latin-1').assign(filename = file)\n",
    "           for file in amazon_customers), ignore_index = True)\n",
    "\n",
    "# combine all shopify csv files (2 because file too large from shopify to download as 1)\n",
    "shopify_customers = sorted(glob('.../orders_export_*.csv'))\n",
    "shopify_all = pd.concat((pd.read_csv(file, encoding='latin-1').assign(filename = file)\n",
    "           for file in shopify_customers), ignore_index = True)\n",
    "\n",
    "print(\"shopify order records: \", shopify_all.shape,\" - amazon order records: \",amazon_all.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Remove duplicate Fulfilled by Amazon orders that are tracked in Shopify and clean data\n",
    "\n",
    "df = shopify_all \n",
    "\n",
    "# delete amazon when source is 'Amazon' or '338151' (amz equivalent) to avoid duplicates\n",
    "df1 = (df.loc[(df['Source'] == 'Amazon')|(df['Source']  == '338151')])\n",
    "shopify_all2 = df.loc[df.index.difference(df1.index), ]\n",
    "df = shopify_all2\n",
    "\n",
    "# if order number was the same, combined to be just 1 order\n",
    "df = df.drop_duplicates(subset='Name',keep='first')\n",
    "\n",
    "# make total orders column and set to 1 since orders haven't been combined\n",
    "df['total_orders'] = 1\n",
    "\n",
    "# delete unnecessary columns\n",
    "df.drop(columns=['Financial Status','Paid at','Fulfillment Status','Fulfilled at',\n",
    "                 'Accepts Marketing','Currency','Subtotal','Shipping','Taxes','Discount Code','Discount Amount',\n",
    "                 'Shipping Method','Lineitem quantity','Lineitem name','Lineitem price',\n",
    "                 'Lineitem compare at price','Lineitem requires shipping','Lineitem taxable',\n",
    "                 'Lineitem fulfillment status','Payment Method','Payment Reference','Refunded Amount',\n",
    "                 'Vendor','Employee','Cancelled at','Outstanding Balance','Location','Phone',\n",
    "                 'Risk Level','Lineitem discount','Tax 1 Name','Tax 1 Value','Tax 2 Name','Tax 2 Value',\n",
    "                 'Tax 3 Name','Tax 3 Value','Tax 4 Name','Tax 4 Value','Tax 5 Name','Tax 5 Value','Receipt Number',\n",
    "                 'Device ID','Id','Notes','Note Attributes','Tags','Billing Address1','Billing Address2',\n",
    "                 'Shipping Address1','Shipping Address2','Lineitem sku'],axis=1,inplace=True)\n",
    "\n",
    "# add Id to each record\n",
    "df = df.reset_index()\n",
    "\n",
    "# rename columns\n",
    "df.rename(columns={'index':'shop_id','Total':'total_spent','Created at':'created_at',\n",
    "                    'Name': 'order_id', 'Email':'email', 'Billing Name':'billing_name',\n",
    "                    'Billing Street':'billing_street', 'Billing Company':'billing_company', \n",
    "                    'Billing City':'billing_city', 'Billing Zip':'billing_zip',\n",
    "                    'Billing Province':'billing_province', 'Billing Country':'billing_country', 'Billing Phone':'billing_phone', \n",
    "                    'Shipping Name':'shipping_name','Shipping Street':'shipping_street', \n",
    "                    'Shipping Company':'shipping_company', 'Shipping City':'shipping_city', 'Shipping Zip':'shipping_zip',\n",
    "                    'Shipping Province':'shipping_province', 'Shipping Country':'shipping_country', \n",
    "                    'Shipping Phone':'phone', 'Source':'source'},inplace=True)\n",
    "\n",
    "# separate crated_at, order_id, source with comma\n",
    "df[['created_at','order_id','source']] = df[['created_at','order_id','source']].astype(str)\n",
    "df['created_at'] = df['created_at'].str[:10]\n",
    "df[['created_at','order_id','source']] = df[['created_at','order_id','source']] + ','\n",
    "\n",
    "# email, name, and addresses are same: sum totals, keep first\n",
    "df = df.groupby(['email','billing_name','shipping_name','billing_street','shipping_street']).agg({'shop_id':'min','total_spent':'sum','total_orders':'sum',\n",
    "                                                                     'billing_company':'first','shipping_company':'first',\n",
    "                                                                     'billing_city':'first','billing_zip':'first','billing_province':'first',\n",
    "                                                                     'billing_country':'first','billing_phone':'first',\n",
    "                                                                     'shipping_province':'first','shipping_city':'first',\n",
    "                                                                     'shipping_zip':'first','shipping_country':'first','phone':'first',\n",
    "                                                                     'created_at':'sum','order_id':'sum','source':'sum'}).reset_index()\n",
    "\n",
    "# create distinct row for each order\n",
    "shopify_all3 = df\n",
    "explode_df3 = (shopify_all3[[\n",
    "                            'email', 'billing_name', 'shipping_name', 'billing_street',\n",
    "                            'shipping_street', 'shop_id','total_spent', 'total_orders', 'billing_company',\n",
    "                            'shipping_company', 'billing_city', 'billing_zip', 'billing_province',\n",
    "                            'billing_country', 'billing_phone', 'shipping_province',\n",
    "                            'shipping_city', 'shipping_zip', 'shipping_country', 'phone',\n",
    "                            'order_id', 'source','created_at'\n",
    "                            ]].set_index([\n",
    "                                                 'email', 'billing_name', 'shipping_name', 'billing_street',\n",
    "                                                 'shipping_street', 'shop_id', 'total_spent', 'total_orders', 'billing_company',\n",
    "                                                 'shipping_company', 'billing_city', 'billing_zip', 'billing_province',\n",
    "                                                 'billing_country', 'billing_phone', 'shipping_province',\n",
    "                                                 'shipping_city', 'shipping_zip', 'shipping_country'])\n",
    "                .apply(lambda x: x.str.split(',').explode())\n",
    "                .reset_index())\n",
    "\n",
    "explode_mask = ~explode_df3['order_id'].isin([\"\"])\n",
    "shopify_all4 = explode_df3[explode_mask]\n",
    "shopify_all4['shop_id'] = 'shop_' + shopify_all4['shop_id'].astype(str)\n",
    "\n",
    "# shopify_all4.head() # check your work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Clean Amazon data\n",
    "\n",
    "df = amazon_all\n",
    "\n",
    "# separate purchase dates with comma\n",
    "df[['purchase-date','sku','amazon-order-id']] = df[['purchase-date','sku','amazon-order-id']].astype(str)\n",
    "df['purchase-date'] = df['purchase-date'].str[:10]\n",
    "df[['purchase-date','sku','amazon-order-id']] = df[['purchase-date','sku','amazon-order-id']] + ','\n",
    "\n",
    "# same orders combined into one with totals summed\n",
    "df = df.groupby(['amazon-order-id']).agg({'sku':'sum','item-price':'sum','item-tax':'sum','shipping-price':'sum',\n",
    "                                     'shipping-tax':'sum','ship-promotion-discount':'sum','item-promotion-discount':'sum',\n",
    "                                     'buyer-email':'first','buyer-name':'first','purchase-date':'first','recipient-name':'first',\n",
    "                                     'ship-address-1':'first','ship-address-2':'first','ship-address-3':'first','ship-city':'first',\n",
    "                                     'ship-state':'first','ship-postal-code':'first','ship-country':'first'}).reset_index()\n",
    "\n",
    "# make total orders column and set to 1 since orders haven't been combined yet\n",
    "df['total_orders'] = 1\n",
    "\n",
    "# add Id to each record\n",
    "df = df.reset_index()\n",
    "\n",
    "# calculate Total Spent equivalent\n",
    "sum_column = (df['item-price'] + df['item-tax'] + df['shipping-price'] + df['shipping-tax'] + df['item-promotion-discount'] + df['ship-promotion-discount'])\n",
    "df['Total Spent'] = sum_column\n",
    "df['Order Value'] = sum_column\n",
    "\n",
    "# join shipping address fields into one (no billing address info given by amz)\n",
    "df['Address'] = df['ship-address-1'].fillna('').astype(str) +' '+ df['ship-address-2'].fillna('').astype(str) +' '+ df['ship-address-3'].fillna('').astype(str)\n",
    "df['Address'] = df['Address'].str.strip()\n",
    "df['Address'] = df['Address'].str.title()\n",
    "\n",
    "# delete unnecessary columns\n",
    "df.drop(columns=['item-price','shipping-price','item-tax','shipping-tax','item-promotion-discount',\n",
    "                 'ship-promotion-discount','ship-address-1','ship-address-2','ship-address-3'],axis=1,inplace=True)\n",
    "\n",
    "# rename columns\n",
    "df.rename(columns={'index':'amz_id','buyer-email':'email','ship-city':'shipping_city','ship-state':'shipping_state','ship-postal-code':'shipping_zip',\n",
    "                    'ship-country':'shipping_country','purchase-date':'created_at','buyer-name':'billing_name','recipient-name':'shipping_name',\n",
    "                    'amazon-order-id':'order_id','Total Spent':'total_spent', 'Order Value':'order_value', 'Address':'address'},inplace=True)\n",
    "\n",
    "# sum totals and delete duplicates when email, name, and address are same\n",
    "df = df.groupby(['email','shipping_name','address']).agg({'amz_id':'min','total_orders':'sum','total_spent':'sum','shipping_city':'first','created_at':'sum',\n",
    "                                                        'shipping_state':'first','shipping_zip':'first','shipping_country':'first',\n",
    "                                                        'billing_name':'first','order_id':'sum'}).reset_index()\n",
    "\n",
    "df = df.groupby(['email','address','billing_name']).agg({'amz_id':'min','total_orders':'sum','total_spent':'sum','shipping_city':'first','shipping_state':'first',\n",
    "                                                        'shipping_zip':'first','shipping_country':'first','shipping_name':'first',\n",
    "                                                        'created_at':'sum','order_id':'sum'}).reset_index()\n",
    "\n",
    "df = df.groupby(['email','address']).agg({'amz_id':'min','total_orders':'sum','total_spent':'sum','shipping_city':'first','shipping_state':'first','shipping_zip':'first',\n",
    "                                            'shipping_country':'first','shipping_name':'first','billing_name':'first','created_at':'sum',\n",
    "                                            'order_id':'sum'}).reset_index()\n",
    "\n",
    "# set channel to amazon\n",
    "df['source'] = 'amazon'\n",
    "\n",
    "amazon_all2 = df\n",
    "explode_amz = (amazon_all2[[\n",
    "                            'email', \n",
    "                            'address', 'amz_id', 'total_orders', 'total_spent', 'shipping_city',\n",
    "                            'shipping_state', 'shipping_zip', 'shipping_country', 'shipping_name',\n",
    "                            'billing_name', 'source',\n",
    "                            'created_at', 'order_id'\n",
    "                            ]].set_index([\n",
    "                                        'email',\n",
    "                                        'address', 'amz_id', 'total_orders', 'total_spent', 'shipping_city',\n",
    "                                        'shipping_state', 'shipping_zip', 'shipping_country', 'shipping_name',\n",
    "                                        'billing_name', 'source'\n",
    "                                        ])\n",
    "                .apply(lambda x: x.str.split(',').explode())\n",
    "                .reset_index())\n",
    "\n",
    "explode_mask_amz = ~explode_amz['order_id'].isin([\"\"])\n",
    "amazon_all3 = explode_amz[explode_mask_amz]\n",
    "amazon_all3['amz_id'] = 'amz_' + amazon_all3['amz_id'].astype(str)\n",
    "\n",
    "# amazon_all3.head() # check your work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Concatenate all data and use group bys to identify like records\n",
    "\n",
    "df1 = shopify_all4 \n",
    "df2 = amazon_all3\n",
    "\n",
    "# combine files\n",
    "df3 = pd.concat([df1,df2])\n",
    "\n",
    "# remove beginning and end spaces\n",
    "df3['shipping_name'] = df3['shipping_name'].str.strip()\n",
    "df3['billing_name'] = df3['billing_name'].str.strip()\n",
    "df3['shipping_city'] = df3['shipping_city'].str.strip()\n",
    "df3['email'] = df3['email'].str.strip()\n",
    "df3['address'] = df3['address'].str.strip()\n",
    "df3['shipping_state'] = df3['shipping_state'].str.strip()\n",
    "df3['shipping_zip'] = df3['shipping_zip'].str.strip()\n",
    "\n",
    "# uniform captitalization\n",
    "df3['address'] = df3['address'].str.lower()\n",
    "df3['shipping_name'] = df3['shipping_name'].str.lower()\n",
    "df3['billing_name'] = df3['billing_name'].str.lower()\n",
    "df3['shipping_city'] = df3['shipping_city'].str.lower()\n",
    "df3['email'] = df3['email'].str.lower()\n",
    "\n",
    "# all zip codes = first 5 numbers\n",
    "df3['shipping_zip'] = df3['shipping_zip'].replace(\"'\", '', regex=True)\n",
    "df3['shipping_zip'] = df3['shipping_zip'].astype(str)\n",
    "df3['shipping_zip'] = df3['shipping_zip'].str[:5] + ' , '\n",
    "\n",
    "# delete double spaces in names\n",
    "df3['shipping_name'] = df3['shipping_name'].replace('\\s+', ' ', regex=True)\n",
    "df3['billing_name'] = df3['billing_name'].replace('\\s+', ' ', regex=True)\n",
    "\n",
    "# add space between strings when summed so able to split & remove duplicates\n",
    "df3['email'] = df3['email'] + ','\n",
    "df3['address'] = df3['address'] + '  &  '\n",
    "df3['shipping_city'] = df3['shipping_city'] + ' , '\n",
    "df3['shipping_state'] = df3['shipping_state'] + ' , '\n",
    "df3['order_id'] = df3['order_id'] + ' , '\n",
    "df3['source'] = df3['source'] + ' , '\n",
    "\n",
    "df3['created_at'] = df3['created_at'].astype(str)\n",
    "df3['created_at'] = df3['created_at'] + ' , '\n",
    "\n",
    "# update id columns \n",
    "df3 = df3.astype(object).replace(np.nan, '')\n",
    "df3['id']=[f\"{a} {b}\" for a,b in zip(df3.amz_id,df3.shop_id)]\n",
    "df3.drop(columns=['amz_id','shop_id'],axis=1,inplace=True)\n",
    "df3['id'] = df3['id'].str.strip()\n",
    "\n",
    "# id: sum totals, keep first - grouping by ids preserves total spent and total orders\n",
    "df3 = df3.groupby(['id']).agg({'shipping_name':'first','email':'first','address':'first','total_orders':'first','total_spent':'first','shipping_city':'first',\n",
    "                                                            'shipping_state':'first','shipping_zip':'first','shipping_country':'first','billing_name':'first',\n",
    "                                                            'shipping_company':'first','phone':'first','created_at':'sum','order_id':'sum','source':'sum'\n",
    "                                                            },axis=1,inplace=True).reset_index()\n",
    "\n",
    "# name, email, address are same: sum totals, keep first\n",
    "df3 = df3.groupby(['shipping_name','email','address']).agg({'total_orders':'sum','total_spent':'sum','shipping_city':'first','id':'first',\n",
    "                                                            'shipping_state':'first','shipping_zip':'first','shipping_country':'first','billing_name':'first',\n",
    "                                                            'shipping_company':'first','phone':'first','created_at':'sum','order_id':'sum','source':'sum'\n",
    "                                                            },axis=1,inplace=True).reset_index()\n",
    "\n",
    "# when shipping name and address same: keep first, sum totals (including email)\n",
    "df3 = df3.groupby(['shipping_name','address']).agg({'total_orders':'sum','total_spent':'sum','shipping_city':'first','email':'sum','id':'first',\n",
    "                                                            'shipping_state':'first','shipping_zip':'first','shipping_country':'first','billing_name':'first',\n",
    "                                                            'shipping_company':'first','phone':'first','created_at':'sum','order_id':'sum','source':'sum'\n",
    "                                                            },axis=1,inplace=True).reset_index()\n",
    "\n",
    "# when billing name and address same: keep first, sum totals (including email)\n",
    "df3 = df3.groupby(['billing_name','address']).agg({'total_orders':'sum','total_spent':'sum','shipping_city':'first','email':'sum','id':'first',\n",
    "                                                            'shipping_state':'first','shipping_zip':'first','shipping_country':'first','shipping_name':'first',\n",
    "                                                            'shipping_company':'first','phone':'first','created_at':'sum','order_id':'sum','source':'sum'\n",
    "                                                            },axis=1,inplace=True).reset_index()\n",
    "\n",
    "# email and address same: sum totals\n",
    "df3 = df3.groupby(['email','address']).agg({'total_orders':'sum','total_spent':'sum','shipping_city':'first','billing_name':'sum','id':'first',\n",
    "                                                            'shipping_state':'first','shipping_zip':'first','shipping_country':'first','shipping_name':'first',\n",
    "                                                            'shipping_company':'first','phone':'first','created_at':'sum','order_id':'sum','source':'sum'\n",
    "                                                            },axis=1,inplace=True).reset_index()\n",
    "\n",
    "\n",
    "# when shipping name, city, state, and zip are same: keep first, sum totals (including email and address)\n",
    "df3 = df3.groupby(['shipping_name','shipping_city']).agg({'total_orders':'sum','total_spent':'sum','address':'first','billing_name':'sum','id':'first',\n",
    "                                                            'shipping_state':'first','shipping_zip':'first','shipping_country':'first','email':'sum',\n",
    "                                                            'shipping_company':'first','phone':'first','created_at':'sum','order_id':'sum','source':'sum'\n",
    "                                                           },axis=1,inplace=True).reset_index()\n",
    "\n",
    "# name and email same: sum totals + address\n",
    "df3 = df3.groupby(['shipping_name','email']).agg({'total_orders':'sum','total_spent':'sum','address':'first','billing_name':'sum','id':'first',\n",
    "                                                            'shipping_state':'first','shipping_zip':'first','shipping_country':'first','shipping_city':'first',\n",
    "                                                            'shipping_company':'first','phone':'first','created_at':'sum','order_id':'sum','source':'sum'\n",
    "                                                           },axis=1,inplace=True).reset_index()\n",
    "\n",
    "df3 = df3.groupby(['billing_name','email']).agg({'total_orders':'sum','total_spent':'sum','address':'first','shipping_name':'sum','id':'first',\n",
    "                                                            'shipping_state':'first','shipping_zip':'first','shipping_country':'first','shipping_city':'first',\n",
    "                                                            'shipping_company':'first','phone':'first','created_at':'sum','order_id':'sum','source':'sum'\n",
    "                                                           },axis=1,inplace=True).reset_index()\n",
    "                                                           \n",
    "# split shipping name into first and last names\n",
    "name = df3['shipping_name'].str.rsplit(' ',1)\n",
    "df3['last_name'] = name.str.get(1)\n",
    "df3['first_name'] = name.str.get(0)\n",
    "\n",
    "# df3.head() # check your work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Continue using groupd bys to identify like records\n",
    "\n",
    "df = df3\n",
    "\n",
    "# take first 3 digits of zipcode\n",
    "df['first3'] = df['shipping_zip'].str[:3]\n",
    "\n",
    "df['created_at'] = df['created_at'].astype(str)\n",
    "\n",
    "# group by same name and first 3 of zip\n",
    "df = df.groupby(['billing_name','first3']).agg({'total_orders':'sum','total_spent':'sum','address':'first','shipping_name':'sum','first_name':'first','last_name':'first',\n",
    "                                                            'shipping_state':'first','shipping_zip':'first','shipping_country':'first','shipping_city':'first','id':'first',\n",
    "                                                            'shipping_company':'first','phone':'first','created_at':'sum','order_id':'sum','source':'sum','email':'sum'\n",
    "                                                           },axis=1,inplace=True).reset_index()\n",
    "\n",
    "# group by same name and first 3 of zip\n",
    "df = df.groupby(['shipping_name','first3']).agg({'total_orders':'sum','total_spent':'sum','address':'first','billing_name':'sum','first_name':'first','last_name':'first',\n",
    "                                                            'shipping_state':'first','shipping_zip':'first','shipping_country':'first','shipping_city':'first','id':'first',\n",
    "                                                            'shipping_company':'first','phone':'first','created_at':'sum','order_id':'sum','source':'sum','email':'sum'\n",
    "                                                           },axis=1,inplace=True).reset_index()\n",
    "\n",
    "# group by same email and first 3 of zip\n",
    "df = df.groupby(['email','first3']).agg({'total_orders':'sum','total_spent':'sum','address':'first','billing_name':'sum','shipping_name':'sum','first_name':'first','id':'first',\n",
    "                                                            'last_name':'first','shipping_state':'first','shipping_zip':'first','shipping_country':'first','shipping_city':'first',\n",
    "                                                            'shipping_company':'first','phone':'first','created_at':'sum','order_id':'sum','source':'sum'\n",
    "                                                           },axis=1,inplace=True).reset_index()\n",
    "\n",
    "# get same intro of email (e.g. johnsmith@gmail.com & johnsmith@yahoo.com\n",
    "begin = df['email'].str.rsplit('@',1)\n",
    "df['intro'] = begin.str.get(0)\n",
    "\n",
    "df = df.groupby(['intro','last_name']).agg({'total_orders':'sum','total_spent':'sum','address':'first','billing_name':'sum','shipping_name':'sum','first_name':'first','id':'first',\n",
    "                                                            'shipping_state':'first','shipping_zip':'first','shipping_country':'first','shipping_city':'first',\n",
    "                                                            'shipping_company':'first','phone':'first','created_at':'sum','order_id':'sum','source':'sum','email':'sum','first3':'sum'\n",
    "                                                           },axis=1,inplace=True).reset_index()\n",
    "\n",
    "df.drop(columns={'intro'},axis=1,inplace=True)\n",
    "\n",
    "# strip spaces from end of row values\n",
    "df['email'] = df['email'].str.strip()\n",
    "df['shipping_city'] = df['shipping_city'].str.strip()\n",
    "df['address'] = df['address'].str.strip()\n",
    "df['shipping_zip'] = df['shipping_zip'].str.strip()\n",
    "df['source'] = df['source'].str.strip()\n",
    "df['shipping_state'] = df['shipping_state'].str.strip()\n",
    "df['created_at'] = df['created_at'].str.strip()\n",
    "\n",
    "combined_df2 = df \n",
    "\n",
    "# explode rows\n",
    "combined_df2.columns\n",
    "\n",
    "explode_comb = (combined_df2[[\n",
    "                            'id', 'email',\n",
    "                            'last_name', 'total_orders', 'total_spent', 'address', 'billing_name',\n",
    "                            'shipping_name', 'first_name',  'shipping_state', 'shipping_zip',\n",
    "                            'shipping_country', 'shipping_city', 'shipping_company', 'phone',\n",
    "                            'created_at', 'order_id', 'source' #to be agregated\n",
    "                            ]].set_index([\n",
    "                                        'id', 'email',\n",
    "                                        'last_name', 'total_orders', 'total_spent', 'address', 'billing_name',\n",
    "                                        'shipping_name', 'first_name',  'shipping_state', 'shipping_zip',\n",
    "                                        'shipping_country', 'shipping_city', 'shipping_company', 'phone'\n",
    "                                        ])\n",
    "                .apply(lambda x: x.str.split(',').explode())\n",
    "                .reset_index())\n",
    "\n",
    "explode_mask_comb = ~explode_comb['created_at'].isin([\"\"])\n",
    "combined_df3 = explode_comb[explode_mask_comb]\n",
    "\n",
    "combined_df3['created_at'] = combined_df3['created_at'].str.strip()\n",
    "combined_df3['order_id'] = combined_df3['order_id'].str.strip()\n",
    "combined_df3 = combined_df3.sort_values(by=['id','created_at'])\n",
    "combined_df3[['shipping_zip','shipping_state','shipping_city']] = combined_df3[['shipping_zip','shipping_state','shipping_city']].replace(',', ' ', regex=True)\n",
    "combined_df3['order_num'] = combined_df3.groupby(['id']).cumcount()+1\n",
    "\n",
    "# combined_df3.shape # check your work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Clean up dates\n",
    "\n",
    "# date for csv export\n",
    "date = pd.to_datetime('today').date()\n",
    "date = date.strftime('yyyy-mm-dd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Produce DF of orders by liked customer\n",
    "# this is the primary output of this process. all calculations from this\n",
    "# point rely on this dataframe\n",
    "\n",
    "# collect order_id, order_email, and skus from shopify\n",
    "df1 = shopify_all\n",
    "df1['sku'] = df1['Lineitem sku'] + ','\n",
    "df1.rename(columns={'Email':'order_email','Name':'source_ord_id','Total':'order_total'},inplace=True)\n",
    "shopify_orders = df1.groupby(['source_ord_id']).agg({\n",
    "                                        'sku':'sum', 'order_email':'first','order_total':'sum'\n",
    "                                        },axis=1,inplace=True).reset_index()\n",
    "\n",
    "# collect order_id, order_email, and skus from amazon\n",
    "df2 = amazon_all\n",
    "df2['sku'] = df2['sku'] + ','\n",
    "sum_column = (df2['item-price'] + df2['item-tax'] + df2['shipping-price'] + df2['shipping-tax'] + df2['item-promotion-discount'] + df2['ship-promotion-discount'])\n",
    "df2['order_total'] = sum_column\n",
    "df2.rename(columns={'buyer-email':'order_email','amazon-order-id':'source_ord_id'},inplace=True)\n",
    "amazon_orders = df2.groupby(['source_ord_id']).agg({\n",
    "                                        'sku':'sum', 'order_email':'first','order_total':'sum'\n",
    "                                        },axis=1,inplace=True).reset_index()\n",
    "\n",
    "# combine amz and shopify order_ids, emails, skus\n",
    "df3 = pd.concat([shopify_orders,amazon_orders])\n",
    "df3['source_ord_id'] = df3['source_ord_id'].replace(',', ' ', regex=True)\n",
    "df3['sku'] = df3['sku'].replace(',,', ',', regex=True)\n",
    "df3['source_ord_id'] = df3['source_ord_id'].str.strip()\n",
    "to_merge = df3\n",
    "\n",
    "# merge sku and email data into record linkage\n",
    "merged_df = combined_df3.merge(to_merge,how='left', left_on='order_id', right_on='source_ord_id')\n",
    "merged_df = merged_df.drop('source_ord_id', axis=1)\n",
    "\n",
    "# identify orders that include skincare \n",
    "conditions = [\n",
    "    (merged_df['sku'].str.contains('TS-CG') == True),\n",
    "    (merged_df['sku'].str.contains('TS-FM') == True),\n",
    "    (merged_df['sku'].str.contains('TS-BL') == True),\n",
    "    (merged_df['sku'].str.contains('TS-FC') == True),\n",
    "    (merged_df['sku'].str.contains('TS-BW') == True),\n",
    "    (merged_df['sku'].str.contains('FACIAL') == True),    \n",
    "    (merged_df['sku'].str.contains('SKIN') == True),\n",
    "    (merged_df['sku'].str.contains('JAMIE') == True)\n",
    "    ]\n",
    "\n",
    "values = [\n",
    "    '1','1','1','1','1','1','1','1'\n",
    "    ]\n",
    "\n",
    "merged_df['skincare'] = np.select(conditions, values)\n",
    "\n",
    "# merged_df.columns # check your work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Identify customers who placed a repeat order in a given year\n",
    "  \n",
    "# create columns listing year and channel of first purchase  \n",
    "df2 = merged_df\n",
    "df2['first_year'] = df2['created_at'].str[:4]\n",
    "df2 = df2.groupby(['id']).agg({\n",
    "            'source':'first','first_year':'first'\n",
    "    },axis=1,inplace=True).reset_index()\n",
    "\n",
    "merged_df = merged_df.drop('first_year', axis=1)\n",
    "\n",
    "df2.rename(columns={'source':'first_source'},inplace=True)\n",
    "df2['first_source'] = df2['first_source'].str.strip()\n",
    "\n",
    "merged_df2 = merged_df.merge(df2, how='left', left_on='id', right_on='id')\n",
    "\n",
    "# create boolean columns for repeat year\n",
    "df = merged_df2\n",
    "\n",
    "cond_r = [df['order_num'] > 1]\n",
    "val_r = [1]\n",
    "df['repeat'] = np.select(cond_r, val_r)\n",
    "df['year_rep'] = df['created_at'].str[:5] + df['repeat'].astype(str)\n",
    "\n",
    "cond_18 = [df['year_rep'].str.contains('2018-1') == True]\n",
    "val_18 = [1]\n",
    "df['repeat_2018'] = np.select(cond_18, val_18)\n",
    "\n",
    "cond_19 = [df['year_rep'].str.contains('2019-1') == True]\n",
    "val_19 = [1]\n",
    "df['repeat_2019'] = np.select(cond_19, val_19)\n",
    "\n",
    "cond_20 = [df['year_rep'].str.contains('2020-1') == True]\n",
    "val_20 = [1]\n",
    "df['repeat_2020'] = np.select(cond_20, val_20)\n",
    "\n",
    "cond_21 = [df['year_rep'].str.contains('2021-1') == True]\n",
    "val_21 = [1]\n",
    "df['repeat_2021'] = np.select(cond_21, val_21)\n",
    "\n",
    "cond_22 = [df['year_rep'].str.contains('2022-1') == True]\n",
    "val_22 = [1]\n",
    "df['repeat_2022'] = np.select(cond_22, val_22)\n",
    "\n",
    "# df.head() # check your work\n",
    "final_rl_df = df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Format data for analysis - i.e boolean ids\n",
    "\n",
    "df = final_rl_df\n",
    "df = df.groupby(['first_source','first_year','id']).agg({\n",
    "        'repeat_2018':'sum','repeat_2019':'sum','repeat_2020':'sum','repeat_2021':'sum','repeat_2022':'sum'\n",
    "    },axis=1, inplace=True).reset_index()\n",
    "\n",
    "unique_cust = df\n",
    "\n",
    "# return count of unique customers\n",
    "print(unique_cust.shape[0],\" unique customer records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Calculate repeat counts by year of first purchase\n",
    "\n",
    "df2 = unique_cust\n",
    "\n",
    "# repeat order count by year of first purchase\n",
    "df3 = df2.groupby(['first_year']).agg({\n",
    "        'id':'count','repeat_2018':'sum','repeat_2019':'sum','repeat_2020':'sum','repeat_2021':'sum'\n",
    "    },axis=1, inplace=True).reset_index()\n",
    "\n",
    "rep_by_first_year = df3\n",
    "\n",
    "# repeat order count by year and channel of first purchase\n",
    "df4 = df2.groupby(['first_source','first_year']).agg({\n",
    "        'id':'count','repeat_2018':'sum','repeat_2019':'sum','repeat_2020':'sum','repeat_2021':'sum'\n",
    "    },axis=1, inplace=True).reset_index()\n",
    "\n",
    "rep_by_first_chan = df4\n",
    "\n",
    "# rep_by_first_year.head() # check your work\n",
    "# rep_by_first_chan.head() # check your work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Calculate cumulative repeat rates\n",
    "\n",
    "df2 = unique_cust\n",
    "\n",
    "df2['rep_by_18'] = df2.apply(lambda x: 1 if (x['repeat_2018'] != 0) else 0, axis = 1)\n",
    "df2['rep_by_19'] = df2.apply(lambda x: 1 if ((x['repeat_2018'] != 0) or (x['repeat_2019'] != 0)) else 0, axis = 1)\n",
    "df2['rep_by_20'] = df2.apply(lambda x: 1 if ((x['repeat_2018'] != 0) or (x['repeat_2019'] != 0) or (x['repeat_2020'] != 0)) else 0, axis = 1)\n",
    "df2['rep_by_21'] =  df2.apply(lambda x: 1 if ((x['repeat_2018'] != 0) or (x['repeat_2019'] != 0) or (x['repeat_2020'] != 0) or (x['repeat_2021'] != 0)) else 0, axis = 1)\n",
    "\n",
    "# cumulative repeat by year of first purchase\n",
    "df3 = df2.groupby(['first_year']).agg({\n",
    "        'id':'count','rep_by_18':'sum','rep_by_19':'sum','rep_by_20':'sum','rep_by_21':'sum'\n",
    "    },axis=1, inplace=True).reset_index()\n",
    "\n",
    "cum_rep_by_first_year = df3\n",
    "\n",
    "# cumulative repeat by year and channel of first purchase\n",
    "df4 = df2.groupby(['first_source','first_year']).agg({\n",
    "        'id':'count','rep_by_18':'sum','rep_by_19':'sum','rep_by_20':'sum','rep_by_21':'sum'\n",
    "    },axis=1, inplace=True).reset_index()\n",
    "\n",
    "cum_rep_by_first_chan = df4\n",
    "\n",
    "# cum_rep_by_first_year.head() # check your work \n",
    "# cum_rep_by_first_chan.head() # check your work"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "fd17d25a996ebc9750db3cfee045d4685def153e86783b5510e9d8a48ea20975"
  },
  "kernelspec": {
   "display_name": "Python 3.8.4 64-bit ('01_ts_code_directory-Xf6xDVFD': pipenv)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
